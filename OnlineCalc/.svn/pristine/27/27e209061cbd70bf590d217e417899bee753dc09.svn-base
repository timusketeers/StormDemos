package com.howbuy.onlinecalc.spout;

import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Properties;

import kafka.consumer.Consumer;
import kafka.consumer.ConsumerConfig;
import kafka.consumer.ConsumerIterator;
import kafka.consumer.KafkaStream;
import kafka.javaapi.consumer.ConsumerConnector;
import backtype.storm.spout.SpoutOutputCollector;
import backtype.storm.task.TopologyContext;
import backtype.storm.topology.OutputFieldsDeclarer;
import backtype.storm.topology.base.BaseRichSpout;
import backtype.storm.tuple.Fields;
import backtype.storm.tuple.Values;

import com.howbuy.onlinecalc.utils.FundUtils;

/**
 * 如果外部有消息发送过来要求我们计算所有基金的最大盈亏的时候，我们才开始计算，我们的拓扑才往下走.
 * @author li.zhang
 *
 */
@SuppressWarnings("serial")
public class TriggerCalcSpout extends BaseRichSpout
{
    private Map<?, ?> conf;
    
    private TopologyContext ctx;
    
    private SpoutOutputCollector collector;
    
    @SuppressWarnings("rawtypes")
    public void open(Map conf, TopologyContext ctx, SpoutOutputCollector collector)
    {
        this.ctx = ctx;
        this.collector = collector;
        this.conf = conf;
    }

    public void nextTuple()
    {
        String topic = "calc_cmd_topic";
        ConsumerConnector consumer = Consumer.createJavaConsumerConnector(createConsumerConfig());
        Map<String, Integer> topickMap = new HashMap<String, Integer>();
        topickMap.put(topic, 1);
        Map<String, List<KafkaStream<byte[], byte[]>>> streamMap = consumer.createMessageStreams(topickMap);
        KafkaStream<byte[], byte[]> stream = streamMap.get(topic).get(0);
        ConsumerIterator<byte[], byte[]> iterator = stream.iterator();

        while (iterator.hasNext())
        {
            System.err.println("get data:" + new String(iterator.next().message()));
            
            //按照每个不同的基金分发到下一个拓扑计算节点.
            List<String> fundCodes = FundUtils.getAllFundCode();
            for (int i = 0; i < fundCodes.size(); i++)
            {
                Values tuple = new Values(fundCodes.get(i));
                collector.emit(tuple);
            }
        }
    }

    public void declareOutputFields(OutputFieldsDeclarer declarer)
    {
        declarer.declare(new Fields("fundcode"));
    }
    
    @Override
    public void ack(Object msgId)
    {
        //所有基金都成功处理完成...
    }

    @Override
    public void fail(Object msgId)
    {
        //中途处理失败.
    }
    
    private ConsumerConfig createConsumerConfig()
    {
        Properties props = new Properties();
        props.put("zookeeper.connect", "slave1.hadoop:2181");
        props.put("group.id", "1");
        props.put("auto.commit.interval.ms", "10000");
        props.put("zookeeper.session.timeout.ms", "10000");
        return new ConsumerConfig(props);
    }

    public Map<?, ?> getConf()
    {
        return conf;
    }

    public TopologyContext getCtx()
    {
        return ctx;
    }

    public SpoutOutputCollector getCollector()
    {
        return collector;
    }
}
